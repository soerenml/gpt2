{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e4b6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.skeleton_gpt2 import GPT\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e00414",
   "metadata": {},
   "source": [
    "# Run the exact GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86ca6cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2-medium\n",
      "------\n",
      "\n",
      "This is the converted hugging face model:\n",
      "\n",
      "------ GPT(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(50257, 1024)\n",
      "    (wpe): Embedding(1024, 1024)\n",
      "    (h): ModuleList(\n",
      "      (0-23): 24 x Block(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): CasualSelfAttention(\n",
      "          (c_attn): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (gelu): GELU(approximate='tanh')\n",
      "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50257, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CasualSelfAttention(\n",
       "          (c_attn): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (gelu): GELU(approximate='tanh')\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_return_sequences = 1\n",
    "max_length = 50\n",
    "\n",
    "model = GPT.from_pretrained(\"gpt2-medium\")\n",
    "model.eval()\n",
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a88b0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "tokens = enc.encode(\"What is the capital of France?\")\n",
    "tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
    "x = tokens.to()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c290fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 7, 50257])\n",
      "torch.Size([5, 8, 50257])\n",
      "torch.Size([5, 9, 50257])\n",
      "torch.Size([5, 10, 50257])\n",
      "torch.Size([5, 11, 50257])\n",
      "torch.Size([5, 12, 50257])\n",
      "torch.Size([5, 13, 50257])\n",
      "torch.Size([5, 14, 50257])\n",
      "torch.Size([5, 15, 50257])\n",
      "torch.Size([5, 16, 50257])\n",
      "torch.Size([5, 17, 50257])\n",
      "torch.Size([5, 18, 50257])\n",
      "torch.Size([5, 19, 50257])\n",
      "torch.Size([5, 20, 50257])\n",
      "torch.Size([5, 21, 50257])\n",
      "torch.Size([5, 22, 50257])\n",
      "torch.Size([5, 23, 50257])\n",
      "torch.Size([5, 24, 50257])\n",
      "torch.Size([5, 25, 50257])\n",
      "torch.Size([5, 26, 50257])\n",
      "torch.Size([5, 27, 50257])\n",
      "torch.Size([5, 28, 50257])\n",
      "torch.Size([5, 29, 50257])\n",
      "torch.Size([5, 30, 50257])\n",
      "torch.Size([5, 31, 50257])\n",
      "torch.Size([5, 32, 50257])\n",
      "torch.Size([5, 33, 50257])\n",
      "torch.Size([5, 34, 50257])\n",
      "torch.Size([5, 35, 50257])\n",
      "torch.Size([5, 36, 50257])\n",
      "torch.Size([5, 37, 50257])\n",
      "torch.Size([5, 38, 50257])\n",
      "torch.Size([5, 39, 50257])\n",
      "torch.Size([5, 40, 50257])\n",
      "torch.Size([5, 41, 50257])\n",
      "torch.Size([5, 42, 50257])\n",
      "torch.Size([5, 43, 50257])\n",
      "torch.Size([5, 44, 50257])\n",
      "torch.Size([5, 45, 50257])\n",
      "torch.Size([5, 46, 50257])\n",
      "torch.Size([5, 47, 50257])\n",
      "torch.Size([5, 48, 50257])\n",
      "torch.Size([5, 49, 50257])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "while x.size(1) < max_length:\n",
    "    with torch.no_grad(): # we are not training the model (no gradient calculation), only using it to generate text\n",
    "        # We pass the current sequence x (tensor of token IDs) to the model\n",
    "        # The model outputs the logits, which represent the unnormalized probabilities of the next token\n",
    "        logits, loss = model(x)\n",
    "        # We start out with a shape of 8 as our input tensor x contains 8 token IDs\n",
    "        # After each iteration, we add a new token to the sequence, so the shape of x grows by 1\n",
    "        print(logits.shape)\n",
    "        # We extract the logits for the last token in the sequence (-1)\n",
    "        # This is because we only care about predicting the next token based on the current context\n",
    "        logits = logits[:, -1, :]\n",
    "        # We apply a softmax function to the logits of the last token\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # torch.topk selects the top 50 probabilities (topk_probs) and their corresponding indices (topk_indices)\n",
    "        # along the last dimension (vocabulary dimension).\n",
    "        # this is an ordered tensor with the highest probabilities at the beginning\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        # E[11]\n",
    "        ix = torch.multinomial(topk_probs, 1)\n",
    "        # We use torch.gather to extract the actual token ID from the top 50 indices (topk_indices) based on the sampled index (ix).\n",
    "        # xcol becomes a one-dimensional tensor containing the sampled token ID.\n",
    "        xcol = torch.gather(topk_indices, -1, ix)\n",
    "        # We concatenate the sampled token ID to the current sequence x.\n",
    "        x = torch.cat((x, xcol), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de9048f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> What is the capital of France?\n",
      "\n",
      "In France, the capital is Lyon. All cities have a capital, as does France's other \"main city\", Nice. If you happen to live in Paris, you can also call the capital a part\n",
      "> What is the capital of France? This question would take several answers, ranging from what most people consider the capital of France to perhaps New York City (the only U.S. city where it is capital of residents rather than citizens). It would be\n",
      "> What is the capital of France?\n",
      "\n",
      "Paris: France.\n",
      "\n",
      "\n",
      "What is the capital of France? Paris: France in modern times.\n",
      "\n",
      "\n",
      "How many capitals is the US? London: about the same number as London in 1850.\n",
      "\n",
      "\n",
      "> What is the capital of France?\n",
      "\n",
      "The capital of France is Paris. Or as we often say French: Paris is capital of France. What is your capital?\n",
      "\n",
      "It depends on the country. We have the capital of France (Paris\n",
      "> What is the capital of France? In ancient times the capital of France was Charlemagne, and he was said to have called it the City of the Sun. In China it has been called Shihuang, to make the point that China is\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_return_sequences):\n",
    "    tokens = x[i, :max_length].tolist()\n",
    "    # Here we decode the token IDs back to text.\n",
    "    decoded = enc.decode(tokens)\n",
    "    print(\">\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0e9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
